{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>    \n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Code-1**  \n",
    "\n",
    "Consider random arrays of shape `a(4,3)` and `b(3,2)`. What is the shape of `a*b` and `np.dot(a,b)`?  \n",
    "`np.dot(a, b)` has shape  = > number of rows of `a`, number of columns of `b` \n",
    "\n",
    "- In numpy the `*` operator indicates element-wise multiplication and is different from `np.dot`.\n",
    "- Dot Product is also known as inner product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7r/_qkccx312r585_l28j8dyq900000gn/T/ipykernel_48388/2005657610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,2) "
     ]
    }
   ],
   "source": [
    "a=np.random.randn(4,3)\n",
    "b=np.random.randn(3,2)\n",
    "c=a*b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">To perform element-wise multiplication, the dimension of both the arrays must be the same.</span>\n",
    "\n",
    "<span style=\"color:brown\">The other method is to broadcating.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  11  24]\n",
      " [ 39  56  75]\n",
      " [ 96 119 144]\n",
      " [171 200 231]]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(12).reshape(4,3)\n",
    "b=np.arange(10,22).reshape(4,3)\n",
    "c=a*b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.random.randn(256,15)\n",
    "b=np.random.randn(15,5)\n",
    "c=np.dot(a,b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform `dot product` on two muti-dimension arrays, the last dimension of the first array should be equal to last but one dimension of second array. So check `a.shape[-1]==b.shape[-2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.shape[-1], b.shape[-2])\n",
    "a.shape[-1] == b.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.randn(3,4)\n",
    "b=np.random.randn(4,1)\n",
    "c=a+b.T\n",
    "print(\"Shape of a+b.T \",c.shape)\n",
    "c=a.T+b\n",
    "print(\"Shape of a.T+b \",c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.randn(3,3)\n",
    "b=np.random.randn(3,1)\n",
    "c=a*b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `np.exp`, `np.log`, and `np.reshape`  ####\n",
    "\n",
    "**sigmoid function, np.exp()**  \n",
    "\n",
    "Implement `np.exp()` and `math.exp()` for the sigmoid function and compare.  \n",
    "\n",
    "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$  \n",
    "\n",
    "<img src=\"images/Sigmoid.png\" style=\"width:500px;height:228px;text-align:center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1/(1+math.exp(-z))\n",
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:brown\"> **Cannot pass array as an arguement**</span>  \n",
    "\n",
    "Give it a try to pass array to find sigmoid function of all the array elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "  return 1/(1+np.exp(-z))\n",
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,2,3])\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if x is a vector, then a Python operation such as $s = x + 3$ or $s = \\frac{1}{x}$ will output s as a vector of the same size as x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a+3\n",
    "b*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52241976 0.50960677 0.34597965]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579], [0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1., -1.1, -3.2],[1.2, 2., 0.1]])\n",
    "A=sigmoid(np.dot(w.T,X)+b)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array corresponding to `(px_x*px_y*3)` and reshape to `(px_x, px_y,3)` and use `image.shape[0]`, `image.shape[1]` and `image.shape[2]`  \n",
    "\n",
    "We can also use `image.reshape(-1,1)` for arranging all elements in a column vector. `-1` represnt unknown rows.  \n",
    "\n",
    "We can also use `(1,-1)` for unknown columns and one row if required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.randn(4*4*3)\n",
    "image=a.reshape(4,4,3)\n",
    "image.shape[0]\n",
    "image.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row Normalization is done by dividing each element of row of a given vector x by its norm based on row.  \n",
    "\n",
    "It is changing x to $ \\frac{x}{\\| x\\|} $.  \n",
    "\n",
    "We get a column vector of norm if we take the square root of the sum of squares of each row elements. Then divide each row by its norm to normalize rows.\n",
    "\n",
    "\n",
    "$$\\| x\\| = \\text{np.linalg.norm(x, axis=1, keepdims=True)}$$  \n",
    "\n",
    "With `keepdims=True` the result will broadcast correctly against the original x.\n",
    "\n",
    "`axis=1` means you are going to get the norm in a row-wise manner. If you need the norm in a column-wise way, you would need to set `axis=0`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm  [[5.        ]\n",
      " [7.28010989]] \n",
      "normalizeRows(x) =  [[0.         0.6        0.8       ]\n",
      " [0.13736056 0.82416338 0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 3, 4],\n",
    "              [1, 6, 4]])\n",
    "x_norm=np.linalg.norm(x, axis=1, keepdims=True)\n",
    "x=x/x_norm\n",
    "print(\"Norm \", x_norm, \"\\nnormalizeRows(x) = \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,4, 5],[3,5,8]])  \n",
    "b=np.sum(a,axis=1)  \n",
    "b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x_exp=np.exp(x)\n",
    "    x_sum=np.sum(x_exp, axis=1).reshape(x.shape[0],1)\n",
    "    s=x_exp/x_sum    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[9, 2, 5, 0, 0],\n",
    "                [7, 5, 0, 0 ,0]])\n",
    "s=softmax(x)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot ----- Computation time = 7.6979999999995385ms\n",
      "dot ----- Computation time = 0.26599999999987745ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = np.arange(10000)\n",
    "x2 = np.arange(10000)\n",
    "\n",
    "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    dot += x1[i] * x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### VECTORIZED DOT PRODUCT OF VECTORS ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"dot ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer = ----- Computation time = 59806.299ms\n",
      "outer =  ----- Computation time = 497.9009999999988ms\n"
     ]
    }
   ],
   "source": [
    "### CLASSIC OUTER PRODUCT IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1), len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i] * x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "### VECTORIZED OUTER PRODUCT ###\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"outer =  ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elementwise multiplication  ----- Computation time = 10.101999999989175ms\n",
      "elementwise multiplication ----- Computation time = 0.24199999998586463ms\n"
     ]
    }
   ],
   "source": [
    "### CLASSIC ELEMENTWISE IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i] * x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication  ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "\n",
    "### VECTORIZED ELEMENTWISE MULTIPLICATION ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdot ----- Computation time = 24.57800000001953ms\n",
      "gdot ----- Computation time = 0.47899999998435305ms\n"
     ]
    }
   ],
   "source": [
    "### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n",
    "W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n",
    "#print(W)\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j] * x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")\n",
    "### VECTORIZED GENERAL DOT PRODUCT ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print (\"gdot ----- Computation time = \" + str(1000 * (toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the numpy vectorized version of the L2 loss. There are several way of implementing the L2 loss but you may find the function np.dot() useful. As a reminder, if $x = [x_1, x_2, ..., x_n]$, then `np.dot(x,x)` = $\\sum_{j=0}^n x_j^{2}$. \n",
    "\n",
    "- L2 loss is defined as $$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(yhat, y):    \n",
    "    loss = np.dot(abs(y-yhat).T, abs(y-yhat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "\n",
    "print(\"L2 = \" + str(L2(yhat, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (Multi Features and m Training Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "We will use $\\mathbf{ùê±_ùê¢}$  to denote the feature vector and  $\\mathbf{ùê≤_ùê¢}$  to denote output variable for $\\mathbf{i^{th}}$ training example.  \n",
    "\n",
    "$h(x)=w_1x^{(i)}_1+w_2x^{(i)}_2+.....+w_{nx}x^{(i)}_{nx}+b$  \n",
    "\n",
    "Where,   \n",
    "\n",
    "$m$ : training examples  \n",
    "$nx$ : Number of features  \n",
    "\n",
    "Let us write $\\hat{y}$ for the prediction from the hypothesis.\n",
    "\n",
    "$\\hat{y}^{(i)} = w_1x^{(i)}_1+w_2x^{(i)}_2+.....+w_{nx}x^{(i)}_{nx}+b $   \n",
    "\n",
    "Feature vector for $i^{th}$ training example:\n",
    "$\\mathbf{x}^{(i)} =\\begin{pmatrix}\n",
    "  {x}_1^{(i)} \\\\ {x}_2^{(i)} \\\\ \\vdots \\\\ {x}_{nx}^{(i)}\n",
    " \\end{pmatrix} $   \n",
    "\n",
    "Feature vector of the problem dataset:   \n",
    "\n",
    "$ \\mathbf{X} = \\begin{pmatrix}\n",
    "\\mathbf{x}^{(1)} & \\mathbf{x}^{(2)} & \\cdots & \\mathbf{x}^{(i)}\n",
    "\\end{pmatrix}$   \n",
    "\n",
    "$ \\mathbf{X} = \\begin{pmatrix}\n",
    "{x}_1^{(1)} & {x}_1^{(2)} & \\cdots & {x}_1^{(m)} \\\\ \n",
    "{x}_2^{(1)} & {x}_2^{(2)} & \\cdots & {x}_2^{(m)} \\\\ \n",
    "\\vdots & \\vdots & \\cdots & \\vdots \\\\ \n",
    "{x}_{nx}^{(1)} & {x}_{nx}^{(1)} & \\cdots & {x}_{nx}^{(m)}\n",
    "\\end{pmatrix}$\n",
    "\n",
    "\n",
    "Parameter vector :\n",
    "$\\mathbf{w} =\\begin{pmatrix}\n",
    "  {w}_1 \\\\ {w}_2 \\\\ \\vdots \\\\ {w}_{nx}\n",
    " \\end{pmatrix}, b $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data   \n",
    "\n",
    "| Size      | Bedrooms | Price (L) |\n",
    "| :---:     | :----:   |   :---:   |\n",
    "| 100       | 1        | 20        |\n",
    "| 150       | 2        | 28        | \n",
    "| 200       | 3        | 39        | \n",
    "| 250       | 4        | 51        | \n",
    "| 500       | 4        | 80        |  \n",
    "\n",
    "$m=5; nx=2$\n",
    "\n",
    "Features for $3^{rd}$ training example:   \n",
    "$$x^{(3)}_1=200; x^{(3)}_2=3$$  \n",
    "\n",
    "Features vector for $2^{nd}$ training example:\n",
    "$\\mathbf{x}^{(2)} =\\begin{pmatrix}\n",
    "  150 \\\\ 2\n",
    " \\end{pmatrix} $   \n",
    "\n",
    "Feature vector of the problem dataset:   \n",
    "\n",
    "$ \\mathbf{X} = \\begin{pmatrix}\n",
    "\\mathbf{x}^{(1)} & \\mathbf{x}^{(2)} & \\cdots & \\mathbf{x}^{(5)}\n",
    "\\end{pmatrix}$   \n",
    "\n",
    "$ \\mathbf{X} = \\begin{pmatrix}\n",
    "100 & 150 & 200 & 250 & 500 \\\\ 1 & 2 & 3 & 4 & 4\n",
    "\\end{pmatrix}$\n",
    "\n",
    "Parameter vector :   \n",
    "$ \\mathbf{w} = \\begin{pmatrix}\n",
    "w_{1} \\\\ w_{2}\n",
    "\\end{pmatrix}, b$  \n",
    "\n",
    "Output vector (Given/Labelled) : \n",
    "$\\mathbf {y} = \\begin{pmatrix}\n",
    "y^{(1)} & y^{(2)} & \\cdots & y^{(m)}\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "20 & 28 & 39 & 53 & 80\n",
    "\\end{pmatrix}$  \n",
    "\n",
    "Output vector (Prediction): \n",
    "$\\mathbf {\\hat{y}} = \\begin{pmatrix}\n",
    "\\hat{y}^{(1)} & \\hat{y}^{(2)} & \\cdots & \\hat{y}^{(m)}\n",
    "\\end{pmatrix} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted Values**   \n",
    "\n",
    "$\\hat{y}^{(1)} = w_1x^{(1)}_1+w_2x^{(1)}_2+b = \\mathbf {w}^T \\mathbf {x}^{(1)} + b $  \n",
    "\n",
    "$\\hat{y}^{(2)} = w_1x^{(2)}_1+w_2x^{(2)}_2+b = \\mathbf {w}^T \\mathbf {x}^{(2)} + b $  \n",
    "\n",
    "$\\hat{y}^{(3)} = w_1x^{(3)}_1+w_2x^{(3)}_2+b = \\mathbf {w}^T \\mathbf {x}^{(3)} + b $  \n",
    "\n",
    "$\\hat{y}^{(4)} = w_1x^{(4)}_1+w_2x^{(4)}_2+b = \\mathbf {w}^T \\mathbf {x}^{(4)} + b $  \n",
    "\n",
    "$\\hat{y}^{(5)} = w_1x^{(5)}_1+w_2x^{(5)}_2+b = \\mathbf {w}^T \\mathbf {x}^{(5)} + b $   \n",
    "\n",
    "\n",
    "$\\mathbf{\\hat{y}} = \\mathbf {w}^T \\mathbf {X} + b $  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  1. ]\n",
      " [1.5 2. ]\n",
      " [2.  3. ]\n",
      " [2.5 4. ]\n",
      " [5.  4. ]] [20 28 39 51 80]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X=np.array([[1,1], [1.5,2], [2,3], [2.5,4],[5,4]])\n",
    "y=np.array([20,28, 39, 51, 80])\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2) <class 'numpy.ndarray'> (5,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "print(X.shape, type(X), y.shape, type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression Object, perform Logistic Regression\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.96  4.42]\n",
      "2.5200000000000102\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Data substitution**   \n",
    "\n",
    "$\\hat{y}^{(1)} = w_1x^{(1)}_1+w_2x^{(1)}_2+b = w_1(100)+w_2(1) + b $    \n",
    "\n",
    "$\\hat{y}^{(2)} = w_1x^{(2)}_1+w_2x^{(2)}_2+b = w_1(150)+w_2(2) + b $    \n",
    "\n",
    "$\\hat{y}^{(3)} = w_1x^{(3)}_1+w_2x^{(3)}_2+b = w_1(200)+w_2(3) + b $    \n",
    "\n",
    "$\\hat{y}^{(4)} = w_1x^{(4)}_1+w_2x^{(4)}_2+b = w_1(250)+w_2(4) + b $    \n",
    "\n",
    "$\\hat{y}^{(5)} = w_1x^{(5)}_1+w_2x^{(5)}_2+b = w_1(500)+w_2(4) + b $    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function  \n",
    "$J(\\mathbf{w},b)=\\frac{1}{2m}\\sum \\limits _{i=1} ^{m} (\\hat{y}^{(i)}-y^{(i)})^{2} $  \n",
    "$J(\\mathbf{w},b)=\\frac{1}{2m}\\sum \\limits _{i=1} ^{m} ((\\mathbf{w}^T \\mathbf{x}^{(i)}+b)-y^{(i)})^{2} $  \n",
    "\n",
    "Start with some assumed value of $\\mathbf{w}$ and $b$ and evaluate $J(\\mathbf{w},b)$  \n",
    "\n",
    "$J(w_1, w_2,b)=\\frac{1}{2m}[(100w_1+w_2+b-20)^2+(150w_1+2w_2+b-28)^2+(200w_1+3w_2+b-39)^2+(250w_1+4w_2+b-51)^2+(500w_1+4w_2+b-80)^2]$  \n",
    "\n",
    "**Our aim is to minimize the cost function,** $J(\\mathbf{w},b)$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "$ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum \\limits _{i=1} ^m (\\hat {y}^{(i)}-y^{(i)}){x}^{(i)}_j$  \n",
    "\n",
    "$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum \\limits _{i=1} ^m (\\hat {y}^{(i)}-y^{(i)})$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Substituting**   \n",
    "\n",
    "$ \\frac{\\partial J}{\\partial w_1} = \\frac{1}{m} [(\\hat {y}^{(1)}-y^{(1)}){x}^{(1)}_1 + (\\hat {y}^{(2)}-y^{(2)}){x}^{(2)}_1 + (\\hat {y}^{(3)}-y^{(3)}){x}^{(3)}_1+(\\hat {y}^{(4)}-y^{(4)}){x}^{(4)}_1 + (\\hat {y}^{(5)}-y^{(5)}){x}^{(5)}_1]$  \n",
    "\n",
    "$ \\frac{\\partial J}{\\partial w_2} = \\frac{1}{m} [(\\hat {y}^{(1)}-y^{(1)}){x}^{(1)}_2 + (\\hat {y}^{(2)}-y^{(2)}){x}^{(2)}_2 + (\\hat {y}^{(3)}-y^{(3)}){x}^{(3)}_2+(\\hat {y}^{(4)}-y^{(4)}){x}^{(4)}_2 + (\\hat {y}^{(5)}-y^{(5)}){x}^{(5)}_2]$   \n",
    "\n",
    "\n",
    "$ \\frac{\\partial J}{\\partial w_1} = \\frac{1}{m} \\begin{pmatrix}\n",
    "{x}^{(1)}_1 & {x}^{(2)}_1 & {x}^{(3)}_1 & {x}^{(4)}_1 & {x}^{(5)}_1 \n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "\\hat {y}^{(1)}-y^{(1)}\\\\\n",
    "\\hat {y}^{(2)}-y^{(2)}\\\\\n",
    "\\hat {y}^{(3)}-y^{(3)}\\\\\n",
    "\\hat {y}^{(4)}-y^{(4)}\\\\\n",
    "\\hat {y}^{(5)}-y^{(5)}\n",
    "\\end{pmatrix}$   \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w_1} = \\frac{1}{m} \\mathbf{x}_{(1)}(\\mathbf{\\hat {y}-y})^T$$  \n",
    "\n",
    "$ \\frac{\\partial J}{\\partial w_2} = \\frac{1}{m} \\begin{pmatrix} \n",
    "{x}^{(1)}_2 & {x}^{(2)}_2 & {x}^{(3)}_2 & {x}^{(4)}_2 & {x}^{(5)}_2\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "\\hat {y}^{(1)}-y^{(1)}\\\\\n",
    "\\hat {y}^{(2)}-y^{(2)}\\\\\n",
    "\\hat {y}^{(3)}-y^{(3)}\\\\\n",
    "\\hat {y}^{(4)}-y^{(4)}\\\\\n",
    "\\hat {y}^{(5)}-y^{(5)}\n",
    "\\end{pmatrix}$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w_2} = \\frac{1}{m} \\mathbf{x}_{(2)}(\\mathbf{\\hat {y}-y})^T$$  \n",
    "\n",
    "$ \\frac {\\partial J}{\\partial \\mathbf{w}} = \\begin{pmatrix}\n",
    "\\frac{\\partial J}{\\partial w_1} \\\\ \n",
    "\\frac{\\partial J}{\\partial w_2}\n",
    "\\end{pmatrix}$ \n",
    "\n",
    "$ \\frac {\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{m}\\begin{pmatrix}\n",
    "{x}^{(1)}_1 & {x}^{(2)}_1 & {x}^{(3)}_1 & {x}^{(4)}_1 & {x}^{(5)}_1 \\\\ \n",
    "{x}^{(1)}_2 & {x}^{(2)}_2 & {x}^{(3)}_2 & {x}^{(4)}_2 & {x}^{(5)}_2\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "\\hat {y}^{(1)}-y^{(1)}\\\\\n",
    "\\hat {y}^{(2)}-y^{(2)}\\\\\n",
    "\\hat {y}^{(3)}-y^{(3)}\\\\\n",
    "\\hat {y}^{(4)}-y^{(4)}\\\\\n",
    "\\hat {y}^{(5)}-y^{(5)}\n",
    "\\end{pmatrix}$ \n",
    "\n",
    "$$ \\frac {\\partial J}{\\partial \\mathbf{w}} =\\frac{1}{m} \\mathbf {X} (\\mathbf{\\hat {y}-y})^{T} $$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Updating Parameters**  \n",
    "\n",
    "$ w_1 = w_1 - \\alpha \\frac {\\partial J}{\\partial w_1}$  \n",
    "\n",
    "$ w_2 = w_2 - \\alpha \\frac {\\partial J}{\\partial w_2}$  \n",
    "\n",
    "In vector form  \n",
    "\n",
    "$ \\mathbf{w} = \\mathbf{w} - \\alpha \\frac {\\partial J}{\\partial \\mathbf{w}}$  \n",
    "\n",
    "$ b = b - \\alpha \\frac {\\partial J}{\\partial b}$  \n",
    "\n",
    "Where,  \n",
    "        $ \\alpha$ : Learning Rate (0.0001, 0.001, 0.01...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python implementation\n",
    "\n",
    "1. Arrange the input feature matrix $ \\mathbf{X}.shape = (nx \\times m)$    \n",
    "2. Arrange the output vector $\\mathbf{y}.shape=(1 \\times m)$  \n",
    "3. Assume learning rate and number of iterations\n",
    "4. Initialize the weight vector $\\mathbf{w}.shape=(nx \\times 1)$ We can initialize these with `zeros` for linear regression.\n",
    "5. Initialize the bias as zero (scalar)\n",
    "6. Loop over iteration  \n",
    "(a) Calculate predicted value array for assumed/updated parameters  \n",
    "$ \\mathbf{\\hat{y}}=\\mathbf{w}^T\\mathbf{X}+b$  \n",
    "(b) Calculate the partial derivative of Cost Function with respect to weights  \n",
    "$ \\frac{\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{m} \\mathbf{X}(\\mathbf{\\hat {y}-y})^T$  \n",
    "(c) Calculate the partial derivative of Cost Function with respect to bias. This is evaluated by summing the difference of predicted value and actual value and taking mean.  \n",
    "$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} Sum(\\mathbf{\\hat {y}-y})^T$  \n",
    "(d) Update the weight and bias  \n",
    "$ \\mathbf{w} = \\mathbf{w} - \\alpha \\frac {\\partial J}{\\partial \\mathbf{w}}$  \n",
    "$ b = b - \\alpha \\frac {\\partial J}{\\partial b}$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5\n",
      "(2, 5) (1, 5) (2, 1) [[0.]\n",
      " [0.]]\n",
      "[[11.95956653]\n",
      " [ 4.42139205]] [2.51672766]\n"
     ]
    }
   ],
   "source": [
    "X_mf=X.T\n",
    "nx,m=X_mf.shape\n",
    "print(nx,m)\n",
    "y=y.reshape(1,X_mf.shape[1])\n",
    "learning_rate=0.001\n",
    "max_iteration=50000\n",
    "# print(X_mf,y)\n",
    "w=np.zeros(nx).reshape(nx,1)\n",
    "J=np.zeros(max_iteration)\n",
    "b=0.0\n",
    "print(X_mf.shape, y.shape, w.shape,w)\n",
    "for i in range(max_iteration):\n",
    "  yhat=np.dot(w.T,X_mf)+b\n",
    "  J[i]=np.dot((yhat-y),(yhat-y).T)*(0.5*m)\n",
    "  # print(\"yhat \", yhat)\n",
    "  dw=(1/m)*np.dot(X_mf,(yhat-y).T)\n",
    "  db=(1/m)*np.sum((yhat-y), axis=1) # axis=1 : Output rowwise sum \n",
    "  w=w-learning_rate*dw\n",
    "  b=b-learning_rate*db\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) (50000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f91ff442e10>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXQklEQVR4nO3df4yVV53H8feHGaC/hbYjQcAFlY1LzYrthGJsNt02ForugokxNLuWdImYLc1q1mSlmmzV2sS60brN1hrcEulGpWzVlDS4yHabdY0pZbC0BWplSmkKoWUstLU2Qge++8c9g8/MPcMMM3PnDnM+r+Rmnvt9ftxz2jt85jznee5VRGBmZjah2Q0wM7OxwYFgZmaAA8HMzBIHgpmZAQ4EMzNLWpvdgKG69NJLY/bs2c1uhpnZWWXHjh2/jYi23LqzNhBmz55NR0dHs5thZnZWkfRCf+sGPGUk6RxJj0t6UtJuSV9O9TmStknqlPSApEmpPjk970zrZ1eOdWuqPytpUaW+ONU6Ja0ZVm/NzGxIBjOHcAy4JiLeD8wHFktaCNwJ3BUR7wGOAivT9iuBo6l+V9oOSfOA5cBlwGLg25JaJLUA9wDXA/OAG9K2ZmY2igYMhKh5Iz2dmB4BXAM8mOrrgWVpeWl6Tlp/rSSl+oaIOBYRzwOdwIL06IyIfRFxHNiQtjUzs1E0qKuM0l/yO4HDwFbgOeDViOhOmxwAZqTlGcCLAGn9a8Al1Xqfffqr59qxSlKHpI6urq7BNN3MzAZpUIEQESciYj4wk9pf9O9tZKNO0461EdEeEe1tbdlJcjMzG6Izug8hIl4FHgU+CEyR1HOV0kzgYFo+CMwCSOvfBrxSrffZp7+6mZmNosFcZdQmaUpaPhf4MPAMtWD4eNpsBfBQWt6UnpPW/0/UPlJ1E7A8XYU0B5gLPA5sB+amq5YmUZt43jQCfTMzszMwmPsQpgPr09VAE4CNEfGwpD3ABklfBZ4A7kvb3wf8h6RO4Ai1f+CJiN2SNgJ7gG5gdUScAJB0C7AFaAHWRcTuEethH+t/uZ+Lz5/EX73/HY16CTOzs5LO1u9DaG9vj6HcmPbhb/4vc6ddwLf/5ooGtMrMbGyTtCMi2nPrivwso7M0A83MGqq4QJCa3QIzs7GpuEAwM7O8IgPBp4zMzOoVFwjC54zMzHKKCwSAwEMEM7O+igsETyqbmeUVFwhmZpZXZCB4UtnMrF6RgWBmZvWKDAQPEMzM6hUXCPKssplZVnGBAJ5DMDPLKS4QPD4wM8srLhDMzCyv0EDwOSMzs76KCwTPKZuZ5RUXCOBJZTOznOICwSMEM7O84gLBzMzyigwEnzEyM6tXXCD4C3LMzPKKCwSA8KyymVmd4gLBk8pmZnnFBQJ4DsHMLGfAQJA0S9KjkvZI2i3pM6n+JUkHJe1MjyWVfW6V1CnpWUmLKvXFqdYpaU2lPkfStlR/QNKkke7oqddq1IHNzM5ygxkhdAOfi4h5wEJgtaR5ad1dETE/PTYDpHXLgcuAxcC3JbVIagHuAa4H5gE3VI5zZzrWe4CjwMoR6p+ZmQ3SgIEQEYci4ldp+XfAM8CM0+yyFNgQEcci4nmgE1iQHp0RsS8ijgMbgKWqfUHBNcCDaf/1wLIh9mdQPKdsZlbvjOYQJM0GPgBsS6VbJD0laZ2kqak2A3ixstuBVOuvfgnwakR096nnXn+VpA5JHV1dXWfS9OpBhrafmdk4N+hAkHQB8CPgsxHxOnAv8G5gPnAI+EYjGlgVEWsjoj0i2tva2oZ+nBFsk5nZeNE6mI0kTaQWBt+PiB8DRMTLlfXfBR5OTw8Csyq7z0w1+qm/AkyR1JpGCdXtR5zHB2ZmeYO5ykjAfcAzEfHNSn16ZbOPAbvS8iZguaTJkuYAc4HHge3A3HRF0SRqE8+bonaX2KPAx9P+K4CHhtctMzM7U4MZIXwI+CTwtKSdqfYFalcJzad2BmY/8GmAiNgtaSOwh9oVSqsj4gSApFuALUALsC4idqfjfR7YIOmrwBPUAqhhfKeymVm9AQMhIn5B/kzL5tPscwdwR6a+ObdfROyjdhVSw3lO2cwsr8g7lc3MrF5xgeABgplZXnGBAL4xzcwsp7hAkCcRzMyyigsEMzPLKzIQwvcqm5nVKS4QfMLIzCyvuEAATyqbmeUUFwieUzYzyysuEMzMLK/IQPApIzOzesUFgjytbGaWVVwggC87NTPLKS8QPEAwM8sqLxDwHIKZWU5xgeABgplZXnGBYGZmeUUGgs8YmZnVKy4QfKeymVlecYEAeIhgZpZRXCD4xjQzs7ziAsHMzPKKDATfqWxmVq+4QPCksplZXnGBAL5T2cwsZ8BAkDRL0qOS9kjaLekzqX6xpK2S9qafU1Ndku6W1CnpKUmXV461Im2/V9KKSv0KSU+nfe6WGvd3vEcIZmZ5gxkhdAOfi4h5wEJgtaR5wBrgkYiYCzySngNcD8xNj1XAvVALEOA24EpgAXBbT4ikbT5V2W/x8LvWPw8QzMzqDRgIEXEoIn6Vln8HPAPMAJYC69Nm64FlaXkpcH/UPAZMkTQdWARsjYgjEXEU2AosTusuiojHIiKA+yvHGnG+7NTMLO+M5hAkzQY+AGwDpkXEobTqJWBaWp4BvFjZ7UCqna5+IFPPvf4qSR2SOrq6us6k6WZmNoBBB4KkC4AfAZ+NiNer69Jf9g0/ExMRayOiPSLa29rahnOcEWyVmdn4MKhAkDSRWhh8PyJ+nMovp9M9pJ+HU/0gMKuy+8xUO119ZqbeEJ5UNjPLG8xVRgLuA56JiG9WVm0Ceq4UWgE8VKnfmK42Wgi8lk4tbQGukzQ1TSZfB2xJ616XtDC91o2VYzWExwdmZvVaB7HNh4BPAk9L2plqXwC+BmyUtBJ4AfhEWrcZWAJ0Am8CNwFExBFJtwPb03ZfiYgjaflm4HvAucBP08PMzEbRgIEQEb+g/y8auzazfQCr+znWOmBdpt4BvG+gtpiZWeP4TmUzMwMKDIQG3gRtZnZWKy4QwJPKZmY5xQWCxwdmZnnFBQLgSQQzs4ziAsFTCGZmecUFgpmZ5RUZCD5hZGZWr7hA8BkjM7O84gIBPKdsZpZTXCD4xjQzs7ziAsHMzPKKDITwtLKZWZ3iAsEnjMzM8ooLBPCksplZTnGB4DllM7O84gIBPEIwM8spMBA8RDAzyykwEMzMLKfIQPAZIzOzesUFgieVzczyigsEgPCssplZneICwQMEM7O84gLBzMzyBgwESeskHZa0q1L7kqSDknamx5LKulsldUp6VtKiSn1xqnVKWlOpz5G0LdUfkDRpJDtoZmaDM5gRwveAxZn6XRExPz02A0iaBywHLkv7fFtSi6QW4B7gemAecEPaFuDOdKz3AEeBlcPp0EA8qWxmljdgIETEz4EjgzzeUmBDRByLiOeBTmBBenRGxL6IOA5sAJaq9uUE1wAPpv3XA8vOrAtnznPKZmb1hjOHcIukp9IppampNgN4sbLNgVTrr34J8GpEdPepN4w8rWxmljXUQLgXeDcwHzgEfGOkGnQ6klZJ6pDU0dXVNeTj+PsQzMzqDSkQIuLliDgRESeB71I7JQRwEJhV2XRmqvVXfwWYIqm1T72/110bEe0R0d7W1jaUpnsOwcysH0MKBEnTK08/BvRcgbQJWC5psqQ5wFzgcWA7MDddUTSJ2sTzpqjdIfYo8PG0/wrgoaG0yczMhqd1oA0k/RC4GrhU0gHgNuBqSfOpfSzQfuDTABGxW9JGYA/QDayOiBPpOLcAW4AWYF1E7E4v8Xlgg6SvAk8A941U5/rjSWUzs3oDBkJE3JAp9/uPdkTcAdyRqW8GNmfq+/jjKaeG8ykjM7O8Iu9U9gDBzKxecYHgy07NzPKKCwQzM8srMhD88ddmZvXKCwSfMTIzyyovEPCksplZTnGB4AGCmVlecYEAeIhgZpZRXCDId6aZmWUVFwhmZpZXZCD4jJGZWb3iAsEnjMzM8ooLBPCNaWZmOcUFgueUzczyigsEMzPLKzIQfMLIzKxecYHgM0ZmZnnFBQL4KzTNzHKKCwTfqWxmlldcIACEZxHMzOoUFwgeH5iZ5RUXCGZmlldkIHhS2cysXnmB4HNGZmZZ5QUCHiGYmeUMGAiS1kk6LGlXpXaxpK2S9qafU1Ndku6W1CnpKUmXV/ZZkbbfK2lFpX6FpKfTPnerwdeFykMEM7OswYwQvgcs7lNbAzwSEXOBR9JzgOuBuemxCrgXagEC3AZcCSwAbusJkbTNpyr79X0tMzMbBQMGQkT8HDjSp7wUWJ+W1wPLKvX7o+YxYIqk6cAiYGtEHImIo8BWYHFad1FEPBa1z6S+v3KshvB9aWZmeUOdQ5gWEYfS8kvAtLQ8A3ixst2BVDtd/UCmniVplaQOSR1dXV1DbLqZmeUMe1I5/WU/KtO0EbE2Itojor2trW04xxnBVpmZjQ9DDYSX0+ke0s/DqX4QmFXZbmaqna4+M1NvGJ8xMjPLG2ogbAJ6rhRaATxUqd+YrjZaCLyWTi1tAa6TNDVNJl8HbEnrXpe0MF1ddGPlWA3j8YGZWb3WgTaQ9EPgauBSSQeoXS30NWCjpJXAC8An0uabgSVAJ/AmcBNARByRdDuwPW33lYjomai+mdqVTOcCP02PhvGksplZ3oCBEBE39LPq2sy2Aazu5zjrgHWZegfwvoHaYWZmjeU7lc3MDCgwEHynsplZXnGBAP6CHDOznOICwZPKZmZ5xQUCeA7BzCynuEDwCMHMLK+4QDAzs7wiA8FnjMzM6hUYCD5nZGaWU2AgeFLZzCynuEDwpLKZWV5xgWBmZnnFBYLwF+SYmeUUFwgTJF9lZGaWUVwgSHDSIwQzszrFBcIEyVcZmZllFBcIHiGYmeUVFwgeIZiZ5RUXCMIjBDOznOICYcIEjxDMzHKKCwTPIZiZ5ZUXCHiEYGaWU1wgTJC/U9nMLKfAQBAnnQdmZnUKDATPIZiZ5QwrECTtl/S0pJ2SOlLtYklbJe1NP6emuiTdLalT0lOSLq8cZ0Xafq+kFcPr0oCN9hyCmVnGSIwQ/jIi5kdEe3q+BngkIuYCj6TnANcDc9NjFXAv1AIEuA24ElgA3NYTIo0wIX0fgj/x1Myst0acMloKrE/L64Fllfr9UfMYMEXSdGARsDUijkTEUWArsLgB7QJqcwiA5xHMzPoYbiAE8DNJOyStSrVpEXEoLb8ETEvLM4AXK/seSLX+6nUkrZLUIamjq6trSA3u+cI0zyOYmfXWOsz9r4qIg5LeDmyV9OvqyogISSP2L29ErAXWArS3tw/puBPSOSPngZlZb8MaIUTEwfTzMPATanMAL6dTQaSfh9PmB4FZld1nplp/9Ybo+U5ljxDMzHobciBIOl/ShT3LwHXALmAT0HOl0ArgobS8CbgxXW20EHgtnVraAlwnaWqaTL4u1RqiZw7BeWBm1ttwThlNA36i2j+wrcAPIuK/JG0HNkpaCbwAfCJtvxlYAnQCbwI3AUTEEUm3A9vTdl+JiCPDaNdpeQ7BzCxvyIEQEfuA92fqrwDXZuoBrO7nWOuAdUNty5k4NUIYjRczMzuLFHensucQzMzyCgyENEI42eSGmJmNMcUFwgSPEMzMsgoMBM8hmJnlFBgItZ8eIZiZ9VZcIHDqs4wcCGZmVcUFQs8IweeMzMx6KzAQ/GmnZmY5BQZC7adPGZmZ9VZcIAjPIZiZ5ZQXCKe+Ma257TAzG2uKCwR/2qmZWV5xgeDPMjIzyysuEHynsplZXnGB0DNCOOHrTs3MeikuECa21LrcfdIfd2pmVlVcIExKgXC824FgZlZVXiC0OhDMzHKKC4SJHiGYmWUVFwinRggnHAhmZlXFBcJknzIyM8sqLhA8QjAzyysvEDyHYGaWVVwgTEwjhGMOBDOzXooLhKnnTQTgyO+PN7klZmZjy5gJBEmLJT0rqVPSmka9znmTWrnonFZeeu0PjXoJM7OzUmuzGwAgqQW4B/gwcADYLmlTROxpxOv92fSLeHDHAV56/Q9Mu2gybRecw9svmszU8yZy/uRWzp/cygWTWzlvUgvnTWqltUVMnDCB1hbROkGo5wORzMzGkTERCMACoDMi9gFI2gAsBRoSCLcvex93bf0Nz3W9Qcf+Ixx9860z2n9ii2jtExCi54PzhMSp5xNOrauFiJQevbbr+R63UTTKLzja/Rvt0PafCDaaHv6Hq5jc2jLixx0rgTADeLHy/ABwZd+NJK0CVgG8853vHPKL/em0C7n3b6849fx490l++8YxXn3zLX5/vJs3jnXz+/R48/gJuk8Eb508SfeJoPvESd46mX6eCE6cDIIgovaR2rWvWUjPA4LgZGWZU9vFqe1H+3NXY5S/C2LUP1d2lF8w/GHqNsoa9SfkWAmEQYmItcBagPb29hH7LZzUOoF3TDmXd0w5d6QOaWZ21hkrk8oHgVmV5zNTzczMRslYCYTtwFxJcyRNApYDm5rcJjOzooyJU0YR0S3pFmAL0AKsi4jdTW6WmVlRxkQgAETEZmBzs9thZlaqsXLKyMzMmsyBYGZmgAPBzMwSB4KZmQGg0b5rdaRI6gJeGOLulwK/HcHmnA3c5zKU1ufS+gvD7/OfRERbbsVZGwjDIakjItqb3Y7R5D6XobQ+l9ZfaGyffcrIzMwAB4KZmSWlBsLaZjegCdznMpTW59L6Cw3sc5FzCGZmVq/UEYKZmfXhQDAzM6CwQJC0WNKzkjolrWl2e86UpHWSDkvaValdLGmrpL3p59RUl6S7U1+fknR5ZZ8Vafu9klZU6ldIejrtc7fGwJdHS5ol6VFJeyTtlvSZVB+3/ZZ0jqTHJT2Z+vzlVJ8jaVtq5wPpo+KRNDk970zrZ1eOdWuqPytpUaU+5n4XJLVIekLSw+n5eO/v/vS+2ympI9Wa+76OiCIe1D5W+zngXcAk4ElgXrPbdYZ9+AvgcmBXpfZ1YE1aXgPcmZaXAD+l9nW/C4FtqX4xsC/9nJqWp6Z1j6dtlfa9fgz0eTpweVq+EPgNMG889zu144K0PBHYltq3EVie6t8B/j4t3wx8Jy0vBx5Iy/PS+3wyMCe9/1vG6u8C8I/AD4CH0/Px3t/9wKV9ak19X5c0QlgAdEbEvog4DmwAlja5TWckIn4OHOlTXgqsT8vrgWWV+v1R8xgwRdJ0YBGwNSKORMRRYCuwOK27KCIei9q76f7KsZomIg5FxK/S8u+AZ6h9B/e47Xdq+xvp6cT0COAa4MFU79vnnv8WDwLXpr8GlwIbIuJYRDwPdFL7PRhzvwuSZgIfAf49PRfjuL+n0dT3dUmBMAN4sfL8QKqd7aZFxKG0/BIwLS3319/T1Q9k6mNGOjXwAWp/MY/rfqfTJzuBw9R+yZ8DXo2I7rRJtZ2n+pbWvwZcwpn/t2imbwH/BJxMzy9hfPcXaiH/M0k7JK1Ktaa+r8fMF+TY8EVESBqX1xFLugD4EfDZiHi9ejp0PPY7Ik4A8yVNAX4CvLe5LWocSR8FDkfEDklXN7k5o+mqiDgo6e3AVkm/rq5sxvu6pBHCQWBW5fnMVDvbvZyGh6Sfh1O9v/6erj4zU286SROphcH3I+LHqTzu+w0QEa8CjwIfpHaaoOePuGo7T/UtrX8b8Apn/t+iWT4E/LWk/dRO51wD/Cvjt78ARMTB9PMwtdBfQLPf182eWBmtB7XR0D5qk009E0uXNbtdQ+jHbHpPKv8LvSehvp6WP0LvSajH44+TUM9Tm4CampYvjvwk1JIx0F9RO//5rT71cdtvoA2YkpbPBf4P+Cjwn/SeZL05La+m9yTrxrR8Gb0nWfdRm2Ads78LwNX8cVJ53PYXOB+4sLL8S2Bxs9/XTX8DjPL/hCXUrlJ5Dvhis9szhPb/EDgEvEXtnOBKaudOHwH2Av9deTMIuCf19WmgvXKcv6M24dYJ3FSptwO70j7/RrqTvcl9voraudangJ3psWQ89xv4c+CJ1OddwD+n+rvSL3kntX8sJ6f6Oel5Z1r/rsqxvpj69SyVq0zG6u8CvQNh3PY39e3J9Njd06Zmv6/90RVmZgaUNYdgZman4UAwMzPAgWBmZokDwczMAAeCmZklDgQzMwMcCGZmlvw/swktSao8i/sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xPlot=np.linspace(1,max_iteration, num=max_iteration)\n",
    "print(xPlot.shape, J.shape)\n",
    "plt.plot(xPlot,J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
